title: "Detecting Drug Seizure Information in Open Source News Articles"
description: "This project uses streaming news data from [`JRC XML Newsfeeds`](https://medisys.newsbrief.eu/rss/?type=category&id=heroinseizure&language=all&duplicates=false) and [GDELT News API](https://blog.gdeltproject.org/gdelt-geo-2-0-api-debuts/) to bootstrap an NER model to detect drug seizures in news articles."
# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  config: "config.cfg"
  name: "dmp_ner_3.0"
  version: "0.0.0"
  train: "train"
  dev: "dev"
  gpu_id: 0

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets", "training", "configs", "scripts", "corpus", "packages"]

# Assets that should be downloaded or available in the directory. We're shipping
# them with the project, so they won't have to be downloaded. But the
# 'project assets' command still lets you verify that the checksums match.
assets:
  - dest: "assets/${vars.train}.json"
    description: "JSONL-formatted training data exported from Prodigy, annotated with `DRUG_SEIZURE` entities (1654 examples)"
  - dest: "assets/${vars.dev}.json"
    description: "JSONL-formatted development data exported from Prodigy, annotated with `DRUG_SEIZURE` entities (535 examples)"


# Workflows are sequences of commands (see below) executed in order. You can
# run them via "spacy project run [workflow]". If a commands's inputs/outputs
# haven't changed, it won't be re-run.
workflows:
  all:
    - preprocess
    - train
    - evaluate

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:
  - name: init-vectors
    help: Download vectors and convert to model
    script:
      - "python -m spacy init vectors en assets/tok2vec_cd8_model289.bin.zip assets/en_tok2vec_vectors"
    deps:
      - "assets/vectors.zip"
    outputs_no_cache:
      - "assets/en_vectors_web_lg"
  - name: "preprocess"
    help: "Convert the data to spaCy's binary format"
    script:
      - "python scripts/preprocess.py assets/${vars.train}.jsonl corpus/${vars.train}.spacy"
      - "python scripts/preprocess.py assets/${vars.dev}.jsonl corpus/${vars.dev}.spacy"
    deps:
      - "assets/${vars.train}.jsonl"
      - "assets/${vars.dev}.jsonl"
      - "scripts/preprocess.py"
    outputs:
      - "corpus/${vars.train}.spacy"
      - "corpus/${vars.dev}.spacy"

  - name: "train"
    help: "Train a named entity recognition model"
    script:
      - "python -m spacy train configs/${vars.config} --output training/ --paths.train corpus/${vars.train}.spacy --paths.dev corpus/${vars.dev}.spacy --gpu-id ${vars.gpu_id}"
    deps:
      - "corpus/${vars.train}.spacy"
      - "corpus/${vars.dev}.spacy"
    outputs:
      - "training/model-best"

  - name: "evaluate"
    help: "Evaluate the model and export metrics"
    script:
      - "python -m spacy evaluate training/model-best corpus/${vars.dev}.spacy --output training/metrics.json"
    deps:
      - "corpus/${vars.dev}.spacy"
      - "training/model-best"
    outputs:
      - "training/metrics.json"

  - name: package
    help: "Package the trained model so it can be installed"
    script:
      - "python -m spacy package training/model-best packages --name ${vars.name} --version ${vars.version} --force"
    deps:
      - "training/model-best"
    outputs_no_cache:
      - "packages/en_${vars.name}-${vars.version}/dist/en_${vars.name}-${vars.version}.tar.gz"

  - name: visualize-model
    help: Visualize the model's output interactively using Streamlit
    script:
      - "streamlit run scripts/visualize_model.py training/model-best \"Police seized 100 kilos of cocaine outside of Quảng Ngãi Province.\""
    deps:
      - "scripts/visualize_model.py"
      - "training/model-best"

  - name: "visualize-data"
    help: "Explore the annotated data in an interactive Streamlit app"
    script:
      - "streamlit run scripts/visualize_data.py assets/${vars.train}.jsonl,assets/${vars.dev}.jsonl"
    deps:
      - "scripts/visualize_data.py"
      - "assets/${vars.train}.jsonl"
      - "assets/${vars.dev}.jsonl"



# Used data-to-spacy to create the training data
# prodigy data-to-spacy ./train-data.json ./eval-data.json --lang en --ner news_ner_person,news_ner_org,news_ner_product --eval-split 0.3

# python -m spacy project run visualize-model


# Spacy Convert Binary JSON into spacy train
# python -m spacy convert assets/train-data.json ./corpus --lang en
# python -m spacy convert assets/eval-data.json ./corpus --lang en

# merged_dataset,ner_dmp_silver_to_gold,eval:dmp_ner_eval


# python -m spacy train configs/config.cfg --output training --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy --paths.init_tok2vec assets/tok2vec_cd8_model289.bin --gpu-id 0

#"python -m spacy train configs/config.cfg --output training/ --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy --training.eval_frequency 10 --training.patience 50 --gpu-id ${vars.gpu_id} --initialize.vectors ${vars.vectors_model} --components.tok2vec.model.embed.include_static_vectors true"